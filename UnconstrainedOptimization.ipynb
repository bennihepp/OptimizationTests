{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for non-linear minimization:\n",
    "- Coordinate descent\n",
    "- Gradient descent\n",
    "- Newton method\n",
    "- BFGS\n",
    "\n",
    "### Methods for non-linear least-squares:\n",
    "- Gauss-newton\n",
    "- Levenberg-Marquardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad as auto_grad, jacobian as auto_jacobian\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_square_with_qr(A, b):\n",
    "    \"\"\"Solve system of equations with square (real values) matrix A: A * x = b\"\"\"\"\"\n",
    "    Q, R = np.linalg.qr(A)\n",
    "    x = scipy.linalg.solve_triangular(R, Q.T @ b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def solve_symm_with_chol(A, b):\n",
    "    \"\"\"Solve system of equations with symmetric (hermitian) matrix A: A * x = b\"\"\"\"\"\n",
    "    c, lower = scipy.linalg.cho_factor(A)\n",
    "    x = scipy.linalg.cho_solve((c, lower), b)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "\n",
    "n0 = 1\n",
    "def objective_fn0(x):\n",
    "    y = -x[..., 0]**2\n",
    "    return y\n",
    "\n",
    "grad_fn0 = auto_grad(objective_fn0)\n",
    "hessian_fn0 = auto_jacobian(grad_fn0)\n",
    "\n",
    "n1 = 1\n",
    "def objective_fn1(x):\n",
    "    y = -100*x[..., 0] + 0.1*x[..., 0]**3 + 0.001*x[..., 0]**4\n",
    "    return y\n",
    "\n",
    "grad_fn1 = auto_grad(objective_fn1)\n",
    "hessian_fn1 = auto_jacobian(grad_fn1)\n",
    "\n",
    "n2 = 2\n",
    "def objective_fn2(x):\n",
    "    y = x[..., 0]**2 - 20*x[..., 0] + 0.4*x[..., 1] + 50*x[..., 1]\n",
    "    return y\n",
    "\n",
    "grad_fn2 = auto_grad(objective_fn2)\n",
    "hessian_fn2 = auto_jacobian(grad_fn2)\n",
    "\n",
    "n3 = 2\n",
    "def objective_fn3(x):\n",
    "    y = x[..., 0]**4 + x[..., 1]**2\n",
    "    return y\n",
    "\n",
    "grad_fn3 = auto_grad(objective_fn3)\n",
    "hessian_fn3 = auto_jacobian(grad_fn3)\n",
    "\n",
    "n4 = 100\n",
    "x_in4 = np.linspace(0, 5, n4)\n",
    "y_out4 = x_in4**2 + 1 * np.random.randn(n4)\n",
    "def residuals_fn4(x):\n",
    "    y = x[..., 0] + x_in4 * x[..., 1] + x_in4**2 * x[..., 2]  - y_out4\n",
    "    return y\n",
    "def objective_fn4(x):\n",
    "    y = np.sum(residuals_fn4(x)**2, axis=x.ndim - 1)\n",
    "    return y\n",
    "\n",
    "residuals_jacobian_fn4 = auto_jacobian(residuals_fn4)\n",
    "grad_fn4 = auto_grad(objective_fn4)\n",
    "hessian_fn4 = auto_jacobian(grad_fn4)\n",
    "\n",
    "n5 = 20\n",
    "x_in5 = np.linspace(0, 100, n5)\n",
    "y_out5 = 100 * np.cos(102 * x_in5) + 102 * np.sin(100 * x_in5)\n",
    "def residuals_fn5(x):\n",
    "    y = x[..., 0] * np.cos(x[..., 1] * x_in5) + x[..., 1] * np.sin(x[..., 0] * x_in5) - y_out5\n",
    "    return y\n",
    "def objective_fn5(x):\n",
    "    y = np.sum(residuals_fn5(x)**2, axis=x.ndim - 1)\n",
    "    return y\n",
    "\n",
    "residuals_jacobian_fn5 = auto_jacobian(residuals_fn5)\n",
    "grad_fn5 = auto_grad(objective_fn5)\n",
    "hessian_fn5 = auto_jacobian(grad_fn5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_coordinate_descent(objective_fn, x0, alpha,\n",
    "                           max_dobj=0., min_step_size=1e-15, obj_tol=1e-12, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    obj_value = objective_fn(x)\n",
    "    coord_index = 0\n",
    "    coord_dir = +1\n",
    "    no_progress_count = 0\n",
    "    while no_progress_count < 2 * len(x) and iteration < max_iterations:\n",
    "        prev_obj_value = obj_value\n",
    "        step_dir = np.zeros(x.shape)\n",
    "        step_dir[coord_index] = coord_dir\n",
    "        step_size = alpha\n",
    "        dobj = float(\"inf\")\n",
    "        x_next = x\n",
    "        while dobj > max_dobj and step_size >= min_step_size:\n",
    "            x_next = x + step_size * step_dir\n",
    "            obj_value = objective_fn(x_next)\n",
    "            dobj = obj_value - prev_obj_value\n",
    "            step_size *= 0.5\n",
    "        if np.abs(dobj) <= obj_tol:\n",
    "            no_progress_count += 1\n",
    "        else:\n",
    "            no_progress_count = 0\n",
    "        x = x_next\n",
    "        iteration += 1\n",
    "        coord_index += 1\n",
    "        if coord_index >= x.shape[-1]:\n",
    "            coord_index = 0\n",
    "            coord_dir = -coord_dir\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"step_dir\": step_dir,\n",
    "        \"step_size\": step_size,\n",
    "        \"no_progress_count\": no_progress_count,\n",
    "    }\n",
    "    return x, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gradient_descent(objective_fn, grad_fn, x0, alpha, max_grad_norm,\n",
    "                         max_dobj=0., min_step_size=1e-15, obj_tol=1e-12, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    obj_value = objective_fn(x)\n",
    "    while np.abs(dobj) > obj_tol and iteration < max_iterations:\n",
    "        prev_obj_value = obj_value\n",
    "        grad = grad_fn(x)\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        if grad_norm > max_grad_norm:\n",
    "            grad *= max_grad_norm / grad_norm\n",
    "        step_dir = -grad\n",
    "        step_size = alpha\n",
    "        dobj = float(\"inf\")\n",
    "        while dobj > max_dobj and step_size >= min_step_size:\n",
    "            x_next = x + step_size * step_dir\n",
    "            obj_value = objective_fn(x_next)\n",
    "            dobj = obj_value - prev_obj_value\n",
    "            step_size *= 0.5\n",
    "        x = x_next\n",
    "        iteration += 1\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"grad\": grad,\n",
    "        \"grad_norm\": grad_norm,\n",
    "        \"step_dir\": step_dir,\n",
    "        \"step_size\": step_size,\n",
    "    }\n",
    "    return x, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_newton_method(objective_fn, grad_fn, hessian_fn, x0, alpha0, max_step_norm,\n",
    "                      max_dobj=0., min_step_size=1e-15, obj_tol=1e-15, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    obj_value = objective_fn(x)\n",
    "    while np.abs(dobj) > obj_tol and iteration < max_iterations:\n",
    "        prev_obj_value = obj_value\n",
    "        grad = grad_fn(x)\n",
    "        hessian = hessian_fn(x)\n",
    "        # Hessian modification\n",
    "        eigvals = np.linalg.eigvalsh(hessian)\n",
    "        if eigvals[0] <= 0:\n",
    "            hessian += (1 + np.abs(eigvals[0])) * np.eye(hessian.shape[0])\n",
    "        step_dir = solve_symm_with_chol(hessian, -grad)\n",
    "#         step_dir = -np.linalg.inv(hessian) @ grad\n",
    "        alpha = alpha0\n",
    "        step = alpha * step_dir\n",
    "        step_norm = np.linalg.norm(step)\n",
    "        if step_norm > max_step_norm:\n",
    "            step_dir *= max_step_norm / (step_norm)\n",
    "        x_next = x\n",
    "        dobj = float(\"inf\")\n",
    "        while dobj > max_dobj and step_norm >= min_step_size:\n",
    "            step = alpha * step_dir\n",
    "            step_norm = np.linalg.norm(step)\n",
    "            x_next = x + step\n",
    "            obj_value = objective_fn(x_next)\n",
    "            dobj = obj_value - prev_obj_value\n",
    "            alpha *= 0.5\n",
    "        x = x_next\n",
    "        iteration += 1\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"grad\": grad,\n",
    "        \"hessian\": hessian,\n",
    "        \"alpha\": alpha,\n",
    "        \"step_dir\": step_dir,\n",
    "        \"step\": step,\n",
    "    }\n",
    "    return x, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_bfgs(objective_fn, grad_fn, x0, alpha0, max_step_norm,\n",
    "                      max_dobj=0., min_step_size=1e-15, divide_tol=1e-15, obj_tol=1e-15, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    #B = np.eye(x.shape[-1])\n",
    "    B_inv = np.eye(x.shape[-1])\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    obj_value = objective_fn(x)\n",
    "    while np.abs(dobj) > obj_tol and iteration < max_iterations:\n",
    "        prev_obj_value = obj_value\n",
    "        grad = grad_fn(x)\n",
    "#         step_dir = solve_symm_with_qr(B, -grad)\n",
    "        #step_dir = -np.linalg.inv(B) @ grad\n",
    "        # Hessian modification\n",
    "        eigvals = np.linalg.eigvalsh(B_inv)\n",
    "        if eigvals[0] <= 0:\n",
    "            B_inv += (1 + np.abs(eigvals[0])) * np.eye(B_inv.shape[0])\n",
    "        step_dir = -B_inv @ grad\n",
    "        alpha = alpha0\n",
    "        step = alpha * step_dir\n",
    "        step_norm = np.linalg.norm(step)\n",
    "        if step_norm > max_step_norm:\n",
    "            step_dir *= max_step_norm / (step_norm)\n",
    "        x_next = x\n",
    "        dobj = float(\"inf\")\n",
    "        while dobj > max_dobj and step_norm >= min_step_size:\n",
    "            step = alpha * step_dir\n",
    "            step_norm = np.linalg.norm(step)\n",
    "            x_next = x + step\n",
    "            obj_value = objective_fn(x_next)\n",
    "            dobj = obj_value - prev_obj_value\n",
    "            alpha *= 0.5\n",
    "        x = x_next\n",
    "        step = step[..., np.newaxis]\n",
    "        y = (grad_fn(x) - grad)[..., np.newaxis]\n",
    "        B_inv_step1_nom = (step.T @ y + y.T @ B_inv @ y) * (step @ step.T)\n",
    "        B_inv_step1_denom = (step.T @ y) ** 2\n",
    "        B_inv_step1 = B_inv_step1_nom / B_inv_step1_denom\n",
    "        B_inv_step2 = - (B_inv @ y @ step.T + step @ y.T @ B_inv) / (step.T @ y)\n",
    "        B_inv += B_inv_step1 + B_inv_step2\n",
    "#         B_step1_denom = y.T @ step\n",
    "#         if np.abs(B_step1_denom) >= divide_tol:\n",
    "#             B_step1 = (y @ y.T) / B_step1_denom\n",
    "#             B_step2 = - (B @ step @ step.T @ B) / (step.T @ B @ step)\n",
    "#             B = B + B_step1 + B_step2\n",
    "        iteration += 1\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"grad\": grad,\n",
    "        \"alpha\": alpha,\n",
    "        \"step_dir\": step_dir,\n",
    "        \"step\": step,\n",
    "#         \"B\": B,\n",
    "        \"B_inv\": B_inv,\n",
    "    }\n",
    "    return x, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gauss_newton(residuals_fn, residuals_jacobian_fn, x0, obj_tol=1e-12, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    residuals = residuals_fn(x)\n",
    "    obj_value = np.sum(residuals**2)\n",
    "    while np.abs(dobj) > obj_tol and iteration < max_iterations:\n",
    "        grad = residuals_jacobian_fn(x)\n",
    "        pseudo_inv = np.linalg.pinv(grad.T @ grad)\n",
    "        step_dir = (pseudo_inv @ grad.T) @ residuals\n",
    "        prev_obj_value = obj_value\n",
    "        step_size = 1\n",
    "        x = x - step_size * step_dir\n",
    "        residuals = residuals_fn(x)\n",
    "        obj_value = np.sum(residuals**2)\n",
    "        dobj = obj_value - prev_obj_value\n",
    "        iteration += 1\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"grad\": grad,\n",
    "        \"step_dir\": step_dir,\n",
    "        \"step_size\": step_size,\n",
    "    }\n",
    "    return x, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_levenberg_marquardt(residuals_fn, residuals_jacobian_fn, x0, lambda0=1., v=2.,\n",
    "                            obj_tol=1e-12, max_iterations=10**6):\n",
    "    x = np.array(x0)\n",
    "    lambda_ = lambda0\n",
    "    iteration = 0\n",
    "    dobj = float(\"inf\")\n",
    "    residuals = residuals_fn(x)\n",
    "    obj_value = np.sum(residuals**2)\n",
    "    while np.abs(dobj) > obj_tol and iteration < max_iterations:\n",
    "        prev_obj_value = obj_value\n",
    "        grad = residuals_jacobian_fn(x)\n",
    "        grad_grad = grad.T @ grad\n",
    "        while True:  # Should max iteration criterion here\n",
    "            lambda1 = lambda_\n",
    "            lambda2 = lambda_ / v\n",
    "            H1 = grad_grad + lambda1 * np.diag(np.diag(grad_grad))\n",
    "            H2 = grad_grad + lambda2 * np.diag(np.diag(grad_grad))\n",
    "            pseudo_inv1 = np.linalg.pinv(H1)\n",
    "            pseudo_inv2 = np.linalg.pinv(H2)\n",
    "            step_dir1 = (pseudo_inv1 @ grad.T) @ residuals\n",
    "            step_dir2 = (pseudo_inv2 @ grad.T) @ residuals\n",
    "            x_next1 = x - step_dir1\n",
    "            x_next2 = x - step_dir2\n",
    "            residuals1 = residuals_fn(x_next1)\n",
    "            residuals2 = residuals_fn(x_next2)\n",
    "            obj_value1 = np.sum(residuals1**2)\n",
    "            obj_value2 = np.sum(residuals2**2)\n",
    "            dobj1 = obj_value1 - prev_obj_value\n",
    "            dobj2 = obj_value2 - prev_obj_value\n",
    "            if dobj1 > 0 and dobj2 > 0:\n",
    "                lambda_ *= v\n",
    "            elif dobj2 < 0:\n",
    "                lambda_ = lambda2\n",
    "                x = x_next2\n",
    "                step_dir = step_dir2\n",
    "                residuals = residuals2\n",
    "                obj_value = obj_value2\n",
    "                dobj = dobj2\n",
    "                break\n",
    "            else:\n",
    "                x = x_next1\n",
    "                step_dir = step_dir1\n",
    "                residuals = residuals1\n",
    "                obj_value = obj_value1\n",
    "                dobj = dobj1\n",
    "                break\n",
    "        iteration += 1\n",
    "    info = {\n",
    "        \"obj_value\": obj_value,\n",
    "        \"dobj\": dobj,\n",
    "        \"obj_tol\": obj_tol,\n",
    "        \"iteration\": iteration,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"grad\": grad,\n",
    "        \"step_dir\": step_dir,\n",
    "    }\n",
    "    return x, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #0 with gradient descent\n",
    "x0 = np.array([2.])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 100\n",
    "x_min, info = min_gradient_descent(objective_fn0, grad_fn0, x0, alpha,\n",
    "                                   max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-np.abs(x_min), +np.abs(x_min), 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn0(x))\n",
    "plt.plot([x_min], [objective_fn0(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #0 with newton method\n",
    "x0 = np.array([2.])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 100\n",
    "x_min, info = min_newton_method(objective_fn0, grad_fn0, hessian_fn0, x0, alpha,\n",
    "                                   max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-np.abs(x_min), +np.abs(x_min), 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn0(x))\n",
    "plt.plot([x_min], [objective_fn0(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #0 with BFGS\n",
    "x0 = np.array([2.])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 100\n",
    "x_min, info = min_bfgs(objective_fn0, grad_fn0, x0, alpha,\n",
    "                                   max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-np.abs(x_min), +np.abs(x_min), 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn0(x))\n",
    "plt.plot([x_min], [objective_fn0(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with scipy BFGS\n",
    "x0 = np.array([1.])\n",
    "import scipy.optimize\n",
    "res = scipy.optimize.minimize(objective_fn0, x0, method=\"BFGS\", jac=grad_fn0)\n",
    "x_min = res.x\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(res.fun))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-np.abs(x_min), +np.abs(x_min), 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn0(x))\n",
    "plt.plot([x_min], [objective_fn0(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with coordinate descent\n",
    "x0 = np.array([+1000.])\n",
    "# x0 = np.array([0.])\n",
    "alpha = 1e6\n",
    "max_iterations = 1000\n",
    "x_min, info = min_coordinate_descent(objective_fn1, x0, alpha, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "print(info)\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with gradient descent\n",
    "x0 = np.array([-20.])\n",
    "# x0 = np.array([0.])\n",
    "alpha = 1e6\n",
    "max_step_norm = float(\"inf\")\n",
    "x_min, info = min_gradient_descent(objective_fn1, grad_fn1, x0, alpha, max_step_norm)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with newton method\n",
    "x0 = np.array([+1000.])\n",
    "# x0 = np.array([0.])\n",
    "alpha = 1e6\n",
    "max_grad_norm = float(\"inf\")\n",
    "max_iterations = 200\n",
    "x_min, info = min_newton_method(objective_fn1, grad_fn1, hessian_fn1, x0, alpha,\n",
    "                                max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "print(info)\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with BFGS\n",
    "x0 = np.array([1000.])\n",
    "alpha = 1e6\n",
    "max_step_norm = float(\"inf\")\n",
    "max_iterations = 1000\n",
    "x_min, info = min_bfgs(objective_fn1, grad_fn1, x0, alpha,\n",
    "                       max_step_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "print(info)\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with scipy BFGS\n",
    "x0 = np.array([-25.])\n",
    "# x0 = np.array([0.])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 500\n",
    "import scipy.optimize\n",
    "res = scipy.optimize.minimize(objective_fn1, x0, method=\"BFGS\", jac=grad_fn1)\n",
    "x_min = res.x\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(res.fun))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with scipy Newton-CG\n",
    "x0 = np.array([-20.])\n",
    "# x0 = np.array([0.])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 500\n",
    "import scipy.optimize\n",
    "res = scipy.optimize.minimize(objective_fn1, x0, method=\"Newton-CG\", jac=grad_fn1)\n",
    "x_min = res.x\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(res.fun))\n",
    "\n",
    "# Plot function and found minimum\n",
    "plt.figure()\n",
    "x = np.linspace(-90, +30, 100)[:, np.newaxis]\n",
    "plt.plot(x, objective_fn1(x))\n",
    "plt.plot([x_min], [objective_fn1(x_min)], 'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #4 with gradient descent\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 1.\n",
    "max_iterations = 1000\n",
    "x_min, info = min_gradient_descent(objective_fn4, grad_fn4, x0, alpha, max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in4, x_min[0] + x_min[1]*x_in4 + x_min[2]*x_in4**2, 'b-')\n",
    "plt.plot(x_in4, y_out4, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #4 with newton method\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "alpha = 10000.\n",
    "max_grad_norm = float(\"inf\")\n",
    "max_iterations = 1000\n",
    "x_min, info = min_newton_method(objective_fn4, grad_fn4, hessian_fn4, x0, alpha,\n",
    "                                max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in4, x_min[0] + x_min[1]*x_in4 + x_min[2]*x_in4**2, 'b-')\n",
    "plt.plot(x_in4, y_out4, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #4 with BFGS\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "alpha = 10000\n",
    "max_step_norm = float(\"inf\")\n",
    "max_iterations = 10000\n",
    "x_min, info = min_bfgs(objective_fn4, grad_fn4, x0, alpha,\n",
    "                       max_step_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in4, x_min[0] + x_min[1]*x_in4 + x_min[2]*x_in4**2, 'b-')\n",
    "plt.plot(x_in4, y_out4, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #4 with gauss newton\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "max_iterations = 100\n",
    "# print(residuals_fn4(x0).shape)\n",
    "# print(residuals_jacobian_fn4(x0).shape)\n",
    "x_min, info = min_gauss_newton(residuals_fn4, residuals_jacobian_fn4, x0, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in4, x_min[0] + x_min[1]*x_in4 + x_min[2]*x_in4**2, 'b-')\n",
    "plt.plot(x_in4, y_out4, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()\n",
    "objective_fn4(x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #4 with levenberg-marquardt\n",
    "\n",
    "x0 = np.array([0.0, 0.0, 0.0])\n",
    "max_iterations = 50\n",
    "# print(residuals_fn4(x0).shape)\n",
    "# print(residuals_jacobian_fn4(x0).shape)\n",
    "x_min, info = min_levenberg_marquardt(residuals_fn4, residuals_jacobian_fn4, x0, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(info[\"obj_value\"]))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in4, x_min[0] + x_min[1]*x_in4 + x_min[2]*x_in4**2, 'b-')\n",
    "plt.plot(x_in4, y_out4, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function #5 along both dimensions\n",
    "\n",
    "xbest = np.array([100., 102.0])\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(xbest[0] - 1, xbest[0] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x, xbest[1]])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(xbest[1] - 1, xbest[1] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([xbest[0], x])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #5 with gradient descent\n",
    "\n",
    "x0 = np.array([100.01, 102.01])\n",
    "alpha = 0.1\n",
    "max_grad_norm = 10.\n",
    "max_iterations = 1000\n",
    "x_min, info = min_gradient_descent(objective_fn5, grad_fn5, x0,\n",
    "                                   alpha, max_grad_norm, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(objective_fn5(x_min)))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in5, x_min[0] * np.cos(x_min[1]*x_in5) + x_min[1] * np.sin(x_min[0]*x_in5), 'b-')\n",
    "plt.plot(x_in5, y_out5, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[0] - 1, x_min[0] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x, x_min[1]])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[0], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[0]\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[1] - 1, x_min[1] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x_min[0], x])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[1], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function fitting #5 with gauss newton\n",
    "\n",
    "x0 = np.array([100.01, 102.01])\n",
    "max_iterations = 1000\n",
    "x_min, info = min_gauss_newton(residuals_fn5, residuals_jacobian_fn5, x0, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(objective_fn5(x_min)))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in5, x_min[0] * np.cos(x_min[1]*x_in5) + x_min[1] * np.sin(x_min[0]*x_in5), 'b-')\n",
    "plt.plot(x_in5, y_out5, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[0] - 1, x_min[0] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x, x_min[1]])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[0], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[0]\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[1] - 1, x_min[1] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x_min[0], x])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[1], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fitting #5 with levenberg-marquardt\n",
    "\n",
    "x0 = np.array([100.01, 102.03])\n",
    "max_iterations = 50\n",
    "x_min, info = min_levenberg_marquardt(residuals_fn5, residuals_jacobian_fn5, x0, max_iterations=max_iterations)\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(objective_fn5(x_min)))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in5, x_min[0] * np.cos(x_min[1]*x_in5) + x_min[1] * np.sin(x_min[0]*x_in5), 'b-')\n",
    "plt.plot(x_in5, y_out5, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[0] - 1, x_min[0] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x, x_min[1]])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[0], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[0]\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[1] - 1, x_min[1] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x_min[0], x])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[1], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize function #1 with scipy BFGS\n",
    "x0 = np.array([100.01, 102.03])\n",
    "import scipy.optimize\n",
    "res = scipy.optimize.minimize(objective_fn5, x0, method=\"BFGS\", jac=grad_fn5)\n",
    "x_min = res.x\n",
    "print(\"minimum x: {}\".format(x_min))\n",
    "print(\"objective value: {}\".format(res.fun))\n",
    "\n",
    "# Plot data and fitted function\n",
    "plt.figure()\n",
    "plt.plot(x_in5, x_min[0] * np.cos(x_min[1]*x_in5) + x_min[1] * np.sin(x_min[0]*x_in5), 'b-')\n",
    "plt.plot(x_in5, y_out5, 'r-')\n",
    "plt.legend([\"Fit\", \"Data\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[0] - 1, x_min[0] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x, x_min[1]])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[0], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[0]\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "X = np.linspace(x_min[1] - 1, x_min[1] + 1, 500)\n",
    "Y = np.array([objective_fn5(np.array([x_min[0], x])) for x in X])\n",
    "plt.plot(X, Y)\n",
    "plt.plot(x_min[1], info[\"obj_value\"], \"rx\")\n",
    "plt.title(\"Plot along x[1]\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
